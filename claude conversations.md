## **How do I ensure that the documentation generated by my python backend script is viewable in your gorgeous frontend? Use the source code from docs_source_code and all the artifacts you created in our most recent conversation for reference.**

**Claude**: I'll help you connect the Python documentation generation backend with the React frontend. Based on the provided code, here's a step-by-step guide:

```python
# 1. First, create a FastAPI backend endpoint to serve the documentation

```python
# backend/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import json
from pathlib import Path

app = FastAPI()

# Configure CORS to allow requests from React frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # React dev server
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/api/documentation/{project_id}")
async def get_documentation(project_id: str):
    """Get documentation for a specific project"""
    # Example path - adjust based on where your documentation is generated
    docs_path = Path(f"documentation/{project_id}/output.json") 
    
    if not docs_path.exists():
        return {"error": "Documentation not found"}
        
    with open(docs_path) as f:
        documentation = json.load(f)
        
    # Transform the documentation into the format expected by the frontend
    formatted_docs = {
        "summary": documentation.get("summary", ""),
        "classes": [
            {
                "name": cls["name"],
                "docstring": cls["docstring"],
                "methods": [
                    {
                        "name": method["name"],
                        "docstring": method["docstring"],
                        "args": method["args"],
                        "async": method.get("async", False),
                        "complexity": method.get("complexity", 0),
                        "type": method.get("type", "instance")
                    }
                    for method in cls.get("methods", [])
                ]
            }
            for cls in documentation.get("classes", [])
        ],
        "functions": [
            {
                "name": func["name"],
                "docstring": func["docstring"],
                "args": func["args"],
                "async": func.get("async", False),
                "complexity": func.get("complexity", 0)
            }
            for func in documentation.get("functions", [])
        ],
        "metrics": {
            "maintainability_index": documentation.get("maintainability_index", 0),
            "complexity": documentation.get("complexity", 0),
            "halstead": documentation.get("halstead", {
                "volume": 0,
                "difficulty": 0,
                "effort": 0
            })
        }
    }
    
    return formatted_docs

# 2. Modify your documentation generation script to output JSON

def write_documentation_report(
    documentation: Dict[str, Any],
    project_id: str,
    output_dir: str = "documentation"
) -> None:
    """Write documentation in JSON format for frontend consumption"""
    output_path = Path(output_dir) / project_id
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Format documentation for frontend
    formatted_docs = {
        "summary": documentation.get("summary", ""),
        "classes": documentation.get("classes", []),
        "functions": documentation.get("functions", []),
        "metrics": {
            "maintainability_index": documentation.get("maintainability_index", 0),
            "complexity": documentation.get("complexity", 0),
            "halstead": documentation.get("halstead", {
                "volume": 0,
                "difficulty": 0,
                "effort": 0
            })
        }
    }
    
    # Write JSON file
    with open(output_path / "output.json", "w") as f:
        json.dump(formatted_docs, f, indent=2)
```

# 3. Update the frontend service to fetch documentation

```typescript
// src/services/documentationService.ts

export const documentationService = {
  async getDocumentation(projectId: string): Promise<Documentation> {
    try {
      const response = await fetch(
        `http://localhost:8000/api/documentation/${projectId}`
      );
      
      if (!response.ok) {
        throw new Error('Failed to fetch documentation');
      }
      
      const data = await response.json();
      
      // Validate the response matches our expected format
      if (!this.isValidDocumentation(data)) {
        throw new Error('Invalid documentation format');  
      }
      
      return data;
    } catch (error) {
      console.error('Error fetching documentation:', error);
      throw error;
    }
  },
  
  // Type guard to validate documentation format
  isValidDocumentation(data: any): data is Documentation {
    return (
      data &&
      typeof data.summary === 'string' &&
      Array.isArray(data.classes) &&
      Array.isArray(data.functions) &&
      typeof data.metrics === 'object'
    );
  }
};

// Update the DocumentationViewer to use the service
import { documentationService } from '../services/documentationService';

const DocumentationViewer: React.FC = () => {
  // ... existing state ...

  useEffect(() => {
    const fetchDocs = async () => {
      try {
        setLoading(true);
        const data = await documentationService.getDocumentation('your-project-id');
        setDocumentation(data);
        setError(null);
      } catch (err) {
        setError(err instanceof Error ? err.message : 'Failed to load documentation');
        console.error('Error fetching documentation:', err);
      } finally {
        setLoading(false);
      }
    };

    fetchDocs();
  }, []);

  // ... rest of component ...
};
```

# 4. Run both servers

1. Start the FastAPI backend:
```bash
cd backend
uvicorn main:app --reload --port 8000
```

2. Start the React frontend:
```bash
cd frontend
npm start
```

# 5. Integration Testing

```python
# backend/tests/test_integration.py
import pytest
from fastapi.testclient import TestClient
from main import app

client = TestClient(app)

def test_get_documentation():
    response = client.get("/api/documentation/test-project")
    assert response.status_code == 200
    data = response.json()
    
    # Verify structure matches frontend expectations
    assert "summary" in data
    assert "classes" in data
    assert "functions" in data
    assert "metrics" in data
    
    # Verify metrics structure
    assert "maintainability_index" in data["metrics"]
    assert "complexity" in data["metrics"]
    assert "halstead" in data["metrics"]

```

Key points for successful integration:

1. Data Format Consistency:
   - The backend must generate JSON documentation that exactly matches the TypeScript interfaces defined in the frontend.
   - All required fields (summary, classes, functions, metrics) must be present.
   - Use consistent naming conventions across both ends.

2. CORS Configuration:
   - The FastAPI backend is configured to allow requests from the React development server.
   - This is crucial for local development.

3. Error Handling:
   - Both backend and frontend implement proper error handling.
   - The frontend displays meaningful error messages to users.
   - The backend provides clear error responses.

4. Type Safety:
   - TypeScript interfaces ensure type safety in the frontend.
   - Type validation in the backend ensures data consistency.

5. Testing:
   - Integration tests verify the correct functioning of the API endpoints.
   - Frontend tests verify proper rendering of documentation.

To view your documentation:

1. Run your Python documentation generation script to generate the JSON output:
```bash
python main.py /path/to/your/project --output-dir documentation
```

2. Start both servers as shown above.

3. Visit http://localhost:3000 in your browser to view the documentation.

The documentation will be displayed with all the visual components (metrics charts, code structure, etc.) as implemented in the React frontend.

Would you like me to provide more details about any specific part of the integration?

---

## **The current main.py is not usable?**

**Claude**:  Let me help you modify the existing `main.py` to output documentation in a format compatible with the frontend viewer. We'll update it while preserving its core functionality.

```python
"""
main.py

This script serves as the main entry point for generating and inserting docstrings into code repositories.
It now includes functionality to output documentation in a format compatible with the frontend viewer.
"""

import aiohttp
import os
import sys
import logging
import argparse
import asyncio
import json
import tracemalloc
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, Optional

from utils import (
    load_config,
    get_all_file_paths,
    DEFAULT_EXCLUDED_DIRS,
    DEFAULT_EXCLUDED_FILES,
    DEFAULT_SKIP_TYPES,
    load_function_schema,
    validate_schema,
)
from file_handlers import process_all_files

# Load environment variables from .env file early
load_dotenv()

# Enable tracemalloc for memory allocation tracking
tracemalloc.start()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler("documentation_generation.log")
    ],
)
logger = logging.getLogger(__name__)

def parse_arguments():
    """Parses command-line arguments."""
    parser = argparse.ArgumentParser(description="Generate and insert docstrings using Azure OpenAI.")
    parser.add_argument("repo_path", help="Path to the code repository")
    parser.add_argument("-c", "--config", help="Path to config.json", default="config.json")
    parser.add_argument("--concurrency", help="Number of concurrent requests", type=int, default=5)
    parser.add_argument("-o", "--output", help="Output Markdown file", default="output.md")
    parser.add_argument("--deployment-name", help="Deployment name for Azure OpenAI", required=True)
    parser.add_argument("--skip-types", help="Comma-separated list of file extensions to skip", default="")
    parser.add_argument("--project-info", help="Information about the project", default="")
    parser.add_argument("--style-guidelines", help="Documentation style guidelines", default="")
    parser.add_argument("--safe-mode", help="Run in safe mode (no files modified)", action="store_true")
    parser.add_argument("--log-level", help="Logging level", default="INFO")
    parser.add_argument("--schema", help="Path to function_schema.json", default="schemas/function_schema.json")
    parser.add_argument("--doc-output-dir", help="Directory to save documentation files", default="documentation")
    parser.add_argument("--project-id", help="Unique identifier for the project", required=True)
    return parser.parse_args()

async def generate_frontend_documentation(documentation_contents: list[str], metrics: Dict[str, Any], project_id: str, output_dir: str):
    """
    Generates documentation in a format compatible with the frontend viewer.
    """
    try:
        # Create output directory
        output_path = Path(output_dir) / project_id
        output_path.mkdir(parents=True, exist_ok=True)

        # Aggregate all documentation
        aggregated_docs = {
            "summary": "",
            "classes": [],
            "functions": [],
            "metrics": {
                "maintainability_index": 0,
                "complexity": 0,
                "halstead": {
                    "volume": 0,
                    "difficulty": 0,
                    "effort": 0
                }
            }
        }

        # Process each documentation content
        for content in documentation_contents:
            if isinstance(content, dict):
                # Update summary
                if content.get("summary"):
                    aggregated_docs["summary"] += content["summary"] + "\n"

                # Aggregate classes
                aggregated_docs["classes"].extend(content.get("classes", []))

                # Aggregate functions
                aggregated_docs["functions"].extend(content.get("functions", []))

                # Update metrics (taking maximum values)
                if content.get("metrics"):
                    current_metrics = aggregated_docs["metrics"]
                    content_metrics = content["metrics"]
                    
                    current_metrics["maintainability_index"] = max(
                        current_metrics["maintainability_index"],
                        content_metrics.get("maintainability_index", 0)
                    )
                    current_metrics["complexity"] = max(
                        current_metrics["complexity"],
                        content_metrics.get("complexity", 0)
                    )

                    # Update Halstead metrics
                    if content_metrics.get("halstead"):
                        for metric in ["volume", "difficulty", "effort"]:
                            current_metrics["halstead"][metric] = max(
                                current_metrics["halstead"][metric],
                                content_metrics["halstead"].get(metric, 0)
                            )

        # Write JSON file for frontend
        json_path = output_path / "documentation.json"
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(aggregated_docs, f, indent=2)

        logger.info(f"Generated frontend-compatible documentation at {json_path}")
        
        # Also generate the markdown file for backup
        md_path = output_path / "documentation.md"
        toc = generate_table_of_contents("\n".join(documentation_contents))
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(f"# Documentation Generation Report\n\n## Table of Contents\n\n{toc}\n\n")
            f.write("\n\n".join(documentation_contents))
        
        logger.info(f"Generated markdown documentation at {md_path}")

    except Exception as e:
        logger.error(f"Error generating frontend documentation: {e}", exc_info=True)
        raise

async def main():
    """Main function to orchestrate the documentation generation process."""
    args = parse_arguments()

    # Configure logging
    numeric_level = getattr(logging, args.log_level.upper(), logging.INFO)
    logger.setLevel(numeric_level)

    repo_path = args.repo_path
    config_path = args.config
    project_id = args.project_id
    output_dir = args.doc_output_dir

    # Validate Azure OpenAI environment variables
    required_vars = {
        'AZURE_OPENAI_API_KEY': os.getenv('AZURE_OPENAI_API_KEY'),
        'AZURE_OPENAI_ENDPOINT': os.getenv('AZURE_OPENAI_ENDPOINT'),
        'API_VERSION': os.getenv('API_VERSION')
    }

    missing_vars = [key for key, value in required_vars.items() if not value]
    if missing_vars or not args.deployment_name:
        logger.critical(f"Missing required environment variables: {', '.join(missing_vars)}")
        sys.exit(1)

    logger.info(f"Processing repository: {repo_path}")
    logger.info(f"Project ID: {project_id}")
    logger.info(f"Output directory: {output_dir}")

    if not os.path.isdir(repo_path):
        logger.critical(f"Invalid repository path: '{repo_path}'")
        sys.exit(1)

    try:
        # Load and process configuration
        excluded_dirs = set(DEFAULT_EXCLUDED_DIRS)
        excluded_files = set(DEFAULT_EXCLUDED_FILES)
        skip_types_set = set(DEFAULT_SKIP_TYPES)
        if args.skip_types:
            skip_types_set.update(ext.strip() for ext in args.skip_types.split(","))

        # Load project info and style guidelines
        project_info, style_guidelines = "", ""
        if os.path.isfile(config_path):
            project_info, style_guidelines = load_config(
                config_path, excluded_dirs, excluded_files, skip_types_set
            )

        project_info = args.project_info or project_info
        style_guidelines = args.style_guidelines or style_guidelines

        # Load and validate function schema
        function_schema = load_function_schema(args.schema)

        # Get file paths
        file_paths = get_all_file_paths(repo_path, excluded_dirs, excluded_files, skip_types_set)

        documentation_contents = []
        async with aiohttp.ClientSession(raise_for_status=True) as session:
            # Process files and collect documentation
            content = await process_all_files(
                session=session,
                file_paths=file_paths,
                skip_types=skip_types_set,
                semaphore=asyncio.Semaphore(args.concurrency),
                deployment_name=args.deployment_name,
                function_schema=function_schema,
                repo_root=repo_path,
                project_info=project_info,
                style_guidelines=style_guidelines,
                safe_mode=args.safe_mode,
                output_file=args.output,
                azure_api_key=required_vars['AZURE_OPENAI_API_KEY'],
                azure_endpoint=required_vars['AZURE_OPENAI_ENDPOINT'],
                azure_api_version=required_vars['API_VERSION'],
                output_dir=output_dir
            )
            
            if content:
                documentation_contents.append(content)

        # Generate frontend-compatible documentation
        await generate_frontend_documentation(
            documentation_contents=documentation_contents,
            metrics={},  # Add aggregated metrics here if needed
            project_id=project_id,
            output_dir=output_dir
        )

        logger.info("Documentation generation completed successfully.")

    except Exception as e:
        logger.critical(f"Unhandled exception: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Process interrupted by user.")
    except Exception as e:
        logger.critical(f"Unhandled exception: {e}", exc_info=True)
        sys.exit(1)

```

Key changes made to the existing `main.py`:

1. Added new `--project-id` argument that's required for frontend integration
2. Added `generate_frontend_documentation()` function that:
   - Creates a JSON file in the format expected by the frontend
   - Aggregates documentation from multiple files
   - Maintains the original markdown output as backup
   - Structures data according to the frontend's TypeScript interfaces

3. Output format matches the frontend's expected structure:
```typescript
interface Documentation {
  summary: string;
  classes: Array<{
    name: string;
    docstring: string;
    methods: Array<{
      name: string;
      docstring: string;
      args: string[];
      async: boolean;
      complexity: number;
      type: string;
    }>;
  }>;
  functions: Array<{
    name: string;
    docstring: string;
    args: string[];
    async: boolean;
    complexity: number;
  }>;
  metrics: {
    maintainability_index: number;
    complexity: number;
    halstead: {
      volume: number;
      difficulty: number;
      effort: number;
    };
  };
}
```

To use the updated script:

1. Run the documentation generation:
```bash
python main.py /path/to/repo \
  --project-id your-project-id \
  --deployment-name your-deployment \
  --doc-output-dir documentation
```

2. This will create:
   - `documentation/your-project-id/documentation.json` - For the frontend
   - `documentation/your-project-id/documentation.md` - Markdown backup

3. The frontend can then access the documentation at `documentation/your-project-id/documentation.json`

Would you like me to also add a FastAPI endpoint to serve the documentation to the frontend, or would you prefer to serve the JSON files directly through your existing server setup?

---

## **What about write_documentation_report.py?**

**Claude**: Yes, we need to update `write_documentation_report.py` to generate output that matches the frontend's expected format. Here's how:

```python
"""
write_documentation_report.py

This module provides functions for generating documentation reports in both JSON (for frontend) 
and Markdown formats. It includes utilities for creating badges, formatting tables, generating 
summaries, and structuring documentation data.
"""

import aiofiles
import re
import json
import os
import textwrap
import logging
import sys
from typing import Optional, Dict, Any, List, Union
from pathlib import Path

from utils import (
    DEFAULT_COMPLEXITY_THRESHOLDS,
    DEFAULT_HALSTEAD_THRESHOLDS,
    DEFAULT_MAINTAINABILITY_THRESHOLDS,
    get_threshold
)

logger = logging.getLogger(__name__)

# ... (keep existing helper functions like generate_badge, format_table, etc.) ...

async def write_documentation_report(
    documentation: Optional[Dict[str, Any]],
    language: str,
    file_path: str,
    repo_root: str,
    output_dir: str
) -> Optional[Dict[str, Any]]:
    """
    Generates documentation in both frontend-compatible JSON and Markdown formats.

    Args:
        documentation: The documentation data.
        language: The programming language.
        file_path: Path to the source file.
        repo_root: Root directory of the repository.
        output_dir: Output directory for documentation.

    Returns:
        Optional[Dict[str, Any]]: The formatted documentation data, or None if generation fails.
    """
    if not documentation:
        logger.warning(f"No documentation to write for '{file_path}'")
        return None

    try:
        # Create output directory
        os.makedirs(output_dir, exist_ok=True)
        relative_path = os.path.relpath(file_path, repo_root)

        # Generate frontend-compatible JSON structure
        frontend_docs = {
            "summary": documentation.get("summary", ""),
            "classes": [
                {
                    "name": cls["name"],
                    "docstring": cls["docstring"],
                    "methods": [
                        {
                            "name": method["name"],
                            "docstring": method["docstring"],
                            "args": method.get("args", []),
                            "async": method.get("async", False),
                            "complexity": method.get("complexity", 0),
                            "type": method.get("type", "instance")
                        }
                        for method in cls.get("methods", [])
                    ]
                }
                for cls in documentation.get("classes", [])
            ],
            "functions": [
                {
                    "name": func["name"],
                    "docstring": func["docstring"],
                    "args": func.get("args", []),
                    "async": func.get("async", False),
                    "complexity": func.get("complexity", 0)
                }
                for func in documentation.get("functions", [])
            ],
            "metrics": {
                "maintainability_index": documentation.get("maintainability_index", 0),
                "complexity": documentation.get("complexity", 0),
                "halstead": documentation.get("halstead", {
                    "volume": 0,
                    "difficulty": 0,
                    "effort": 0
                })
            }
        }

        # Also generate Markdown content for reference
        markdown_content = await generate_markdown_content(documentation, language, file_path, relative_path)

        # Write both formats
        safe_filename = sanitize_filename(os.path.basename(file_path))
        base_path = Path(output_dir) / safe_filename

        # Write JSON for frontend
        json_path = base_path.with_suffix('.json')
        async with aiofiles.open(json_path, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(frontend_docs, indent=2))

        # Write Markdown for reference
        md_path = base_path.with_suffix('.md')
        async with aiofiles.open(md_path, 'w', encoding='utf-8') as f:
            await f.write(markdown_content)

        logger.info(f"Documentation written to {json_path} and {md_path}")
        return frontend_docs

    except Exception as e:
        logger.error(f"Error writing documentation report: {e}", exc_info=True)
        return None

async def generate_markdown_content(
    documentation: Dict[str, Any],
    language: str,
    file_path: str,
    relative_path: str
) -> str:
    """Generates enhanced markdown content with collapsible sections and better formatting."""
    
    # Generate table of contents
    toc = [
        "# Table of Contents\n",
        "1. [Overview](#overview)",
        "2. [Code Structure](#code-structure)",
        "3. [Dependencies](#dependencies)",
        "4. [Metrics](#metrics)",
        "\n---\n"
    ]

    # Generate Overview section
    overview = [
        "# Overview\n",
        f"**File:** `{os.path.basename(file_path)}`  ",
        f"**Language:** {language}  ",
        f"**Path:** `{relative_path}`  \n",
        "## Summary\n",
        f"{documentation.get('summary', 'No summary available.')}\n",
        "## Recent Changes\n",
        "\n".join(f"- {change}" for change in documentation.get('changes_made', ['No recent changes.'])),
        "\n"
    ]

    # Generate Code Structure section
    code_structure = ["# Code Structure\n"]
    
    if documentation.get("classes"):
        code_structure.append("## Classes\n")
        code_structure.append(format_classes(documentation["classes"]))

    if documentation.get("functions"):
        code_structure.append("## Functions\n")
        code_structure.append(format_functions(documentation["functions"]))

    # Generate Dependencies section
    dependencies = [
        "# Dependencies\n",
        "```mermaid",
        "graph TD;",
    ]
    
    # Create dependency graph
    dep_map = {}
    for dep in documentation.get('variables', []) + documentation.get('constants', []):
        if dep.get('type') == 'import':
            dep_name = dep['name']
            dep_refs = dep.get('references', [])
            dep_map[dep_name] = dep_refs
            dependencies.append(f"    {dep_name}[{dep_name}];")
    
    for dep, refs in dep_map.items():
        for ref in refs:
            if ref in dep_map:
                dependencies.append(f"    {dep} --> {ref};")
    
    dependencies.extend(["```\n"])

    # Generate Metrics section
    metrics = [
        "# Metrics\n",
        "## Code Quality\n",
        generate_all_badges(
            complexity=documentation.get("complexity"),
            halstead=documentation.get("halstead"),
            mi=documentation.get("maintainability_index")
        ),
        "\n"
    ]

    if "halstead" in documentation:
        halstead = documentation["halstead"]
        metrics.extend([
            "## Halstead Metrics\n",
            "| Metric | Value |",
            "|--------|--------|",
            f"| Volume | {halstead.get('volume', 0):.1f} |",
            f"| Difficulty | {halstead.get('difficulty', 0):.1f} |",
            f"| Effort | {halstead.get('effort', 0):.1f} |",
        ])

    # Combine all sections
    content = "\n".join([
        *toc,
        *overview,
        *code_structure,
        *dependencies,
        *metrics
    ])

    return content

# ... (keep existing helper functions) ...

def get_metric_status(value: float) -> str:
    """Returns a status indicator based on metric value."""
    if value >= 80:
        return "✅ Good"
    elif value >= 60:
        return "⚠️ Warning"
    return "❌ Needs Improvement"

def sanitize_filename(filename: str) -> str:
    """Sanitizes filename by removing invalid characters."""
    return re.sub(r'[<>:"/\\|?*]', '_', filename)

```

Key changes made to `write_documentation_report.py`:

1. Now generates two output formats:
   - JSON format compatible with the frontend viewer
   - Markdown format for reference and backup

2. The JSON format strictly follows the frontend's TypeScript interfaces:
   - Classes with methods
   - Functions with arguments and complexity
   - Metrics including maintainability index and Halstead metrics

3. Enhanced error handling and logging

4. Structured the documentation in a way that maps directly to the frontend components

To use the updated module:

```python
# Example usage in process_file():
documentation = await write_documentation_report(
    documentation=generated_docs,
    language=language,
    file_path=file_path,
    repo_root=repo_root,
    output_dir=output_dir
)
```

The output will be:

```
output_dir/
├── example_file.json  # For frontend
└── example_file.md    # For reference
```

The JSON file (`example_file.json`) will contain:
```json
{
  "summary": "...",
  "classes": [
    {
      "name": "ExampleClass",
      "docstring": "...",
      "methods": [
        {
          "name": "example_method",
          "docstring": "...",
          "args": ["arg1", "arg2"],
          "async": false,
          "complexity": 3,
          "type": "instance"
        }
      ]
    }
  ],
  "functions": [...],
  "metrics": {
    "maintainability_index": 85,
    "complexity": 10,
    "halstead": {
      "volume": 245.6,
      "difficulty": 12.3,
      "effort": 3021.4
    }
  }
}
```

This format ensures that the documentation data can be consumed directly by the React frontend components without any additional transformation.

Would you like me to explain any specific part in more detail or show how to integrate this with specific frontend components?

---
## **Just updated the write_documentation_report.py so that its format ensures that the documentation data can be consumed directly by the React frontend components without any additional transformation. I need you to show how to integrate this with specific frontend components, as well as any other modifications that the python script needs to cooperate.**

I'll help you integrate the updated `write_documentation_report.py` with the React frontend components and suggest any necessary modifications. Let me analyze this step by step.



```typescript
import React from 'react';
import { useDocumentation } from '../hooks/useDocumentation';
import { MetricsOverview } from './metrics/MetricsOverview';
import { ClassesList } from './documentation/ClassesList';
import { CodeViewer } from './code/CodeViewer';
import { DetailedMetrics } from './metrics/DetailedMetrics';
import { LoadingSpinner, ErrorDisplay } from './common';

// Updated interface to match Python output
interface Documentation {
  summary: string;
  classes: Array<{
    name: string;
    docstring: string;
    methods: Array<{
      name: string;
      docstring: string;
      args: string[];
      async: boolean;
      complexity: number;
      type: string;
    }>;
  }>;
  functions: Array<{
    name: string;
    docstring: string;
    args: string[];
    async: boolean;
    complexity: number;
  }>;
  metrics: {
    maintainability_index: number;
    complexity: number;
    halstead: {
      volume: number;
      difficulty: number;
      effort: number;
    };
  };
}

const DocumentationViewer: React.FC = () => {
  // Use the custom hook for documentation data
  const { documentation, loading, error } = useDocumentation({
    projectId: 'your-project-id',
    // Optional: specify file path for single file documentation
    filePath: 'path/to/file' 
  });

  if (loading) return <LoadingSpinner />;
  if (error) return <ErrorDisplay message={error} />;
  if (!documentation) return <ErrorDisplay message="No documentation available" />;

  return (
    <div className="space-y-8">
      {/* Summary Section */}
      <div className="prose dark:prose-invert">
        <h1>Documentation Overview</h1>
        <p>{documentation.summary}</p>
      </div>

      {/* Metrics Overview */}
      <MetricsOverview
        metrics={documentation.metrics}
        functionCount={documentation.functions.length}
        classCount={documentation.classes.length}
      />

      {/* Classes List */}
      <ClassesList classes={documentation.classes} />

      {/* Code View */}
      <CodeViewer documentation={documentation} />

      {/* Detailed Metrics */}
      <DetailedMetrics metrics={documentation.metrics} />
    </div>
  );
};

export default DocumentationViewer;

// Custom hook implementation
const useDocumentation = ({ projectId, filePath }: { projectId: string; filePath?: string }) => {
  const [documentation, setDocumentation] = React.useState<Documentation | null>(null);
  const [loading, setLoading] = React.useState(true);
  const [error, setError] = React.useState<string | null>(null);

  React.useEffect(() => {
    const fetchDocumentation = async () => {
      try {
        setLoading(true);
        const response = await fetch(
          `/api/documentation?project_id=${projectId}${filePath ? `&file_path=${filePath}` : ''}`
        );
        if (!response.ok) throw new Error('Failed to fetch documentation');
        const data = await response.json();
        setDocumentation(data);
      } catch (err) {
        setError(err instanceof Error ? err.message : 'An error occurred');
      } finally {
        setLoading(false);
      }
    };

    fetchDocumentation();
  }, [projectId, filePath]);

  return { documentation, loading, error };
};

```

```python
# Update write_documentation_report.py

import json
from typing import Dict, Any, Optional
from pathlib import Path

async def write_documentation_report(
    documentation: Optional[Dict[str, Any]],
    language: str,
    file_path: str,
    repo_root: str,
    output_dir: str
) -> Optional[Dict[str, Any]]:
    """
    Generates frontend-compatible documentation format.
    """
    if not documentation:
        logger.warning(f"No documentation to write for '{file_path}'")
        return None

    try:
        # Create frontend-compatible structure
        frontend_docs = {
            "summary": documentation.get("summary", ""),
            "classes": [
                {
                    "name": cls["name"],
                    "docstring": cls["docstring"],
                    "methods": [
                        {
                            "name": method["name"],
                            "docstring": method["docstring"],
                            "args": method.get("args", []),
                            "async": method.get("async", False),
                            "complexity": method.get("complexity", 0),
                            "type": method.get("type", "instance")
                        }
                        for method in cls.get("methods", [])
                    ]
                }
                for cls in documentation.get("classes", [])
            ],
            "functions": [
                {
                    "name": func["name"],
                    "docstring": func["docstring"],
                    "args": func.get("args", []),
                    "async": func.get("async", False),
                    "complexity": func.get("complexity", 0)
                }
                for func in documentation.get("functions", [])
            ],
            "metrics": {
                "maintainability_index": documentation.get("maintainability_index", 0),
                "complexity": documentation.get("complexity", 0),
                "halstead": documentation.get("halstead", {
                    "volume": 0,
                    "difficulty": 0,
                    "effort": 0
                })
            }
        }

        # Ensure output directory exists
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Write JSON for frontend
        json_file = output_path / f"{Path(file_path).stem}.json"
        async with aiofiles.open(json_file, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(frontend_docs, indent=2))

        # Also write Markdown version if needed
        if documentation.get("generate_markdown", True):
            md_file = output_path / f"{Path(file_path).stem}.md"
            markdown_content = await generate_markdown_content(
                documentation, language, file_path, repo_root
            )
            async with aiofiles.open(md_file, 'w', encoding='utf-8') as f:
                await f.write(markdown_content)

        logger.info(f"Documentation written to {json_file}")
        return frontend_docs

    except Exception as e:
        logger.error(f"Error writing documentation report: {e}", exc_info=True)
        return None

# Add API endpoint handler
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse

app = FastAPI()

@app.get("/api/documentation")
async def get_documentation(project_id: str, file_path: Optional[str] = None):
    try:
        # Load the documentation file
        doc_path = Path(f"documentation/{project_id}")
        if file_path:
            doc_file = doc_path / f"{Path(file_path).stem}.json"
        else:
            # Return all documentation files for the project
            doc_files = list(doc_path.glob("*.json"))
            if not doc_files:
                raise HTTPException(status_code=404, message="No documentation found")
            doc_file = doc_files[0]  # Return first file by default

        async with aiofiles.open(doc_file, 'r', encoding='utf-8') as f:
            content = await f.read()
            return JSONResponse(content=json.loads(content))

    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Documentation not found")
    except Exception as e:
        logger.error(f"Error fetching documentation: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal server error")

```

The above artifacts demonstrate:

1. Frontend Integration:
- Updated TypeScript interfaces matching the Python output format
- React components structured to consume the documentation data
- Custom hook for fetching documentation
- Loading and error states handling

2. Python Updates:
- Structured JSON output matching frontend needs
- FastAPI endpoint for serving documentation
- Error handling and logging
- Support for both single file and project-wide documentation

Key Integration Points:

1. **Data Format Consistency**: The Python script now generates JSON that exactly matches the TypeScript interfaces, eliminating the need for data transformation on the frontend.

2. **API Integration**: The FastAPI endpoint serves the documentation in the exact format needed by the React components.

3. **Error Handling**: Both backend and frontend handle errors consistently and provide appropriate feedback.

To use this integration:

1. Ensure the Python backend is running and generating documentation:
```bash
uvicorn main:app --reload
```

2. Start the React frontend:
```bash
cd documentation-system/client
npm start
```

3. Access documentation through the frontend:
```typescript
const { documentation, loading, error } = useDocumentation({
  projectId: 'your-project-id',
  filePath: 'optional/file/path'
});
```

The Python script needs these modifications to work smoothly:

1. Add proper CORS handling to FastAPI:
```python
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

2. Add project configuration handling:
```python
@app.get("/api/projects/{project_id}/config")
async def get_project_config(project_id: str):
    try:
        config_path = Path(f"documentation/{project_id}/config.json")
        async with aiofiles.open(config_path, 'r', encoding='utf-8') as f:
            return JSONResponse(content=json.loads(await f.read()))
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Project configuration not found")
```

Would you like me to provide more details about any specific part of this integration?

---
## **How do we integrate the current file_handlers.py, specifically the fetch_documentation_rest function, the process_file function and the generate_documentation_prompt from write_documentation_report.py**

I'll help you integrate these components to work seamlessly together. Let me show you how to modify and connect these functions.



```python
"""
file_handlers.py

Integrated version that connects file processing, OpenAI API calls,
and documentation generation into a cohesive pipeline.
"""

import asyncio
import aiohttp
import json
import logging
from typing import Dict, Any, Optional, List
from pathlib import Path

from language_functions import get_handler
from context_manager import ContextManager

logger = logging.getLogger(__name__)

async def process_file(
    session: aiohttp.ClientSession,
    file_path: str,
    skip_types: set,
    semaphore: asyncio.Semaphore,
    deployment_name: str,
    function_schema: Dict[str, Any],
    repo_root: str,
    project_info: str,
    style_guidelines: str,
    azure_api_key: str,
    azure_endpoint: str,
    azure_api_version: str,
    output_dir: str,
) -> Optional[Dict[str, Any]]:
    """
    Processes a single file through the documentation pipeline.
    
    Args:
        session: aiohttp session for API calls
        file_path: Path to the source file
        skip_types: File types to skip
        semaphore: Rate limiting semaphore
        deployment_name: Azure OpenAI deployment name
        function_schema: Schema for documentation structure
        repo_root: Repository root path
        project_info: Project context information
        style_guidelines: Documentation style guidelines
        azure_api_key: Azure OpenAI API key
        azure_endpoint: Azure OpenAI endpoint
        azure_api_version: Azure API version
        output_dir: Output directory for documentation
    
    Returns:
        Optional[Dict[str, Any]]: Generated documentation or None if processing fails
    """
    if not should_process_file(file_path, skip_types):
        return None

    try:
        # Prepare file content and get appropriate handler
        content, language, handler = await prepare_file(file_path, function_schema)
        if not all([content, language, handler]):
            return None

        # Extract code structure
        code_structure = await extract_code_structure(content, file_path, language, handler)
        if not code_structure:
            return None

        # Generate documentation prompt
        context = ContextManager.get_relevant_context(file_path)
        prompt = generate_documentation_prompt(
            file_name=Path(file_path).name,
            code_structure=code_structure,
            project_info=f"{project_info}\n\nContext:\n{context}",
            style_guidelines=style_guidelines,
            language=language,
            function_schema=function_schema
        )

        # Get documentation from OpenAI
        documentation = await fetch_documentation_rest(
            session=session,
            prompt=prompt,
            semaphore=semaphore,
            deployment_name=deployment_name,
            function_schema=function_schema,
            azure_api_key=azure_api_key,
            azure_endpoint=azure_endpoint,
            azure_api_version=azure_api_version
        )

        if not documentation:
            logger.error(f"Failed to generate documentation for {file_path}")
            return None

        # Update metrics and structure
        documentation.update({
            "file_path": str(Path(file_path).relative_to(repo_root)),
            "language": language,
            "metrics": code_structure.get("metrics", {}),
            "structure": code_structure
        })

        # Write documentation to files
        result = await write_documentation_report(
            documentation=documentation,
            language=language,
            file_path=file_path,
            repo_root=repo_root,
            output_dir=output_dir
        )

        return result

    except Exception as e:
        logger.error(f"Error processing file {file_path}: {e}", exc_info=True)
        return None

async def fetch_documentation_rest(
    session: aiohttp.ClientSession,
    prompt: str,
    semaphore: asyncio.Semaphore,
    deployment_name: str,
    function_schema: Dict[str, Any],
    azure_api_key: str,
    azure_endpoint: str,
    azure_api_version: str,
    retry: int = 3,
    backoff_factor: float = 2.0
) -> Optional[Dict[str, Any]]:
    """
    Fetches documentation from Azure OpenAI API with enhanced error handling and retry logic.
    """
    url = f"{azure_endpoint}/openai/deployments/{deployment_name}/chat/completions?api-version={azure_api_version}"
    headers = {
        "Content-Type": "application/json",
        "api-key": azure_api_key,
    }

    payload = {
        "messages": [{"role": "user", "content": prompt}],
        "functions": function_schema.get("functions", []),
        "function_call": {"name": "generate_documentation"}
    }

    for attempt in range(retry):
        try:
            async with semaphore:
                async with session.post(url, headers=headers, json=payload) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        if "choices" not in data or not data["choices"]:
                            logger.error("No choices in API response")
                            continue

                        choice = data["choices"][0]
                        message = choice.get("message", {})
                        
                        if "function_call" not in message:
                            logger.error("No function_call in message")
                            continue

                        function_call = message["function_call"]
                        if function_call.get("name") != "generate_documentation":
                            logger.error(f"Unexpected function call: {function_call.get('name')}")
                            continue

                        try:
                            documentation = json.loads(function_call.get("arguments", "{}"))
                            # Validate the response
                            if validate_documentation(documentation, function_schema):
                                return documentation
                            logger.error("Documentation validation failed")
                        except json.JSONDecodeError as e:
                            logger.error(f"Error decoding JSON response: {e}")
                            logger.debug(f"Raw arguments: {function_call.get('arguments')}")

                    elif response.status == 429:  # Rate limit
                        retry_after = float(response.headers.get("Retry-After", backoff_factor ** attempt))
                        logger.warning(f"Rate limited. Waiting {retry_after} seconds...")
                        await asyncio.sleep(retry_after)
                        continue
                    else:
                        error_text = await response.text()
                        logger.error(f"API request failed: {response.status} - {error_text}")

        except aiohttp.ClientError as e:
            logger.error(f"Network error: {e}")
        except Exception as e:
            logger.error(f"Unexpected error: {e}")

        if attempt < retry - 1:
            wait_time = backoff_factor ** attempt
            logger.warning(f"Retrying in {wait_time} seconds... (Attempt {attempt + 1}/{retry})")
            await asyncio.sleep(wait_time)

    logger.error("All retry attempts failed")
    return None

def generate_documentation_prompt(
    file_name: str,
    code_structure: Dict[str, Any],
    project_info: str,
    style_guidelines: str,
    language: str,
    function_schema: Dict[str, Any]
) -> str:
    """
    Generates an enhanced prompt for documentation generation.
    """
    docstring_format = function_schema["functions"][0]["parameters"]["properties"]["docstring_format"]["enum"][0]
    
    # Get relevant metrics
    metrics = code_structure.get("metrics", {})
    complexity = metrics.get("complexity", "unknown")
    maintainability = metrics.get("maintainability_index", "unknown")
    
    # Extract key components
    classes = code_structure.get("classes", [])
    functions = code_structure.get("functions", [])
    variables = code_structure.get("variables", [])
    
    prompt = f"""
    As an expert documentation generator, analyze and document the following {language} file: '{file_name}'.
    
    Context:
    {project_info}

    Code Metrics:
    - Complexity: {complexity}
    - Maintainability Index: {maintainability}

    Style Requirements:
    {style_guidelines}

    File Structure:
    - Classes: {len(classes)}
    - Functions: {len(functions)}
    - Variables: {len(variables)}

    Documentation Requirements:
    1. Use {docstring_format} style
    2. Include detailed descriptions of functionality
    3. Document all parameters and return values
    4. Note any important dependencies or requirements
    5. Provide usage examples where appropriate
    6. Highlight any potential issues or considerations

    Code Structure:
    {json.dumps(code_structure, indent=2)}

    Generate comprehensive documentation that strictly follows this schema:
    {json.dumps(function_schema["functions"][0]["parameters"], indent=2)}

    Focus on clarity, completeness, and maintainability. Include examples and edge cases where relevant.
    """
    
    return textwrap.dedent(prompt).strip()

def validate_documentation(
    documentation: Dict[str, Any],
    schema: Dict[str, Any]
) -> bool:
    """
    Validates the documentation against the schema with detailed error reporting.
    """
    try:
        params_schema = schema["functions"][0]["parameters"]
        validate(instance=documentation, schema=params_schema)
        return True
    except ValidationError as e:
        logger.error("Documentation validation failed:")
        for error in e.path:
            logger.error(f"- {' -> '.join(str(p) for p in error.path)}: {error.message}")
        return False
    except Exception as e:
        logger.error(f"Unexpected validation error: {e}")
        return False

```

```python
"""
process_manager.py

Manages concurrent processing of files and coordinates documentation generation.
"""

import asyncio
import aiohttp
from typing import List, Set, Dict, Any
from pathlib import Path

from file_handlers import process_file
from context_manager import ContextManager

class DocumentationProcessManager:
    def __init__(
        self,
        repo_root: str,
        output_dir: str,
        azure_config: Dict[str, str],
        function_schema: Dict[str, Any],
        max_concurrency: int = 5
    ):
        self.repo_root = Path(repo_root)
        self.output_dir = Path(output_dir)
        self.azure_config = azure_config
        self.function_schema = function_schema
        self.semaphore = asyncio.Semaphore(max_concurrency)
        self.context_manager = ContextManager()

    async def process_files(
        self,
        file_paths: List[str],
        skip_types: Set[str],
        project_info: str,
        style_guidelines: str
    ) -> Dict[str, Any]:
        """
        Processes multiple files concurrently with proper error handling and progress tracking.
        """
        async with aiohttp.ClientSession() as session:
            tasks = []
            results = {
                "successful": [],
                "failed": [],
                "skipped": []
            }

            for file_path in file_paths:
                if not self._should_process(file_path, skip_types):
                    results["skipped"].append(file_path)
                    continue

                task = asyncio.create_task(
                    self._process_single_file(
                        session=session,
                        file_path=file_path,
                        skip_types=skip_types,
                        project_info=project_info,
                        style_guidelines=style_guidelines
                    )
                )
                tasks.append(task)

            # Process files with progress tracking
            completed = 0
            total = len(tasks)
            
            for future in asyncio.as_completed(tasks):
                try:
                    result = await future
                    if result:
                        results["successful"].append(result)
                    else:
                        results["failed"].append(result)
                except Exception as e:
                    logger.error(f"Task failed: {e}")
                    results["failed"].append(str(e))

                completed += 1
                self._update_progress(completed, total)

            return results

    async def _process_single_file(
        self,
        session: aiohttp.ClientSession,
        file_path: str,
        skip_types: Set[str],
        project_info: str,
        style_guidelines: str
    ) -> Optional[Dict[str, Any]]:
        """
        Processes a single file with context management and error handling.
        """
        try:
            # Get relevant context for the file
            file_context = self.context_manager.get_relevant_context(file_path)
            enhanced_project_info = f"{project_info}\n\nFile Context:\n{file_context}"

            result = await process_file(
                session=session,
                file_path=file_path,
                skip_types=skip_types,
                semaphore=self.semaphore,
                deployment_name=self.azure_config["deployment_name"],
                function_schema=self.function_schema,
                repo_root=str(self.repo_root),
                project_info=enhanced_project_info,
                style_guidelines=style_guidelines,
                azure_api_key=self.azure_config["api_key"],
                azure_endpoint=self.azure_config["endpoint"],
                azure_api_version=self.azure_config["api_version"],
                output_dir=str(self.output_dir)
            )

            if result:
                # Update context with successful documentation
                self.context_manager.add_context(
                    f"File: {file_path}\nDocumentation Summary: {result.get('summary', '')}"
                )

            return result

        except Exception as e:
            logger.error(f"Error processing {file_path}: {e}")
            return None

    def _should_process(self, file_path: str, skip_types: Set[str]) -> bool:
        """
        Determines if a file should be processed based on various criteria.
        """
        path = Path(file_path)
        return (
            path.exists() and
            path.suffix.lower() not in skip_types and
            not path.name.startswith('.') and
            not any(part.startswith('.') for part in path.parts)
        )

    def _update_progress(self, completed: int, total: int):
        """
        Updates and displays progress information.
        """
        percentage = (completed / total) * 100
        logger.info(f"Progress: {completed}/{total} files ({percentage:.1f}%)")

# Usage example:
async def main():
    azure_config = {
        "deployment_name": os.getenv("AZURE_OPENAI_DEPLOYMENT"),
        "api_key": os.getenv("AZURE_OPENAI_API_KEY"),
        "endpoint": os.getenv("AZURE_OPENAI_ENDPOINT"),
        "api_version": os.getenv("AZURE_OPENAI_API_VERSION")
    }

    manager = DocumentationProcessManager(
        repo_root="path/to/repo",
        output_dir="path/to/output",
        azure_config=azure_config,
        function_schema=load_function_schema("path/to/schema.json")
    )

    results = await manager.process_files(
        file_paths=["file1.py", "file2.py"],
        skip_types={".pyc", ".pyo"},
        project_info="Project context...",
        style_guidelines="Documentation guidelines..."
    )

    print(f"Successfully processed: {len
```

---
## **Continue**

I'll continue with the implementation, showing how these components work together and how to handle the results.



```python
"""
process_manager.py (continued)

Completes the implementation with results handling and frontend integration.
"""

import asyncio
import aiohttp
from typing import List, Set, Dict, Any, Optional
from pathlib import Path
from fastapi import FastAPI, BackgroundTasks, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

class DocumentationRequest(BaseModel):
    project_id: str
    file_paths: List[str]
    skip_types: Set[str] = set()
    project_info: str
    style_guidelines: str

class DocumentationResponse(BaseModel):
    task_id: str
    status: str
    progress: float
    results: Optional[Dict[str, Any]] = None

class DocumentationProcessManager:
    def __init__(
        self,
        repo_root: str,
        output_dir: str,
        azure_config: Dict[str, Any],
        function_schema: Dict[str, Any],
        max_concurrency: int = 5
    ):
        self.repo_root = Path(repo_root)
        self.output_dir = Path(output_dir)
        self.azure_config = azure_config
        self.function_schema = function_schema
        self.semaphore = asyncio.Semaphore(max_concurrency)
        self.context_manager = ContextManager()
        self.active_tasks: Dict[str, Dict[str, Any]] = {}

    async def process_files(
        self,
        task_id: str,
        file_paths: List[str],
        skip_types: Set[str],
        project_info: str,
        style_guidelines: str
    ) -> Dict[str, Any]:
        """
        Processes files and tracks progress for frontend monitoring.
        """
        self.active_tasks[task_id] = {
            "status": "running",
            "progress": 0.0,
            "results": {
                "successful": [],
                "failed": [],
                "skipped": []
            }
        }

        try:
            async with aiohttp.ClientSession() as session:
                tasks = []
                for file_path in file_paths:
                    if not self._should_process(file_path, skip_types):
                        self.active_tasks[task_id]["results"]["skipped"].append(file_path)
                        continue

                    task = asyncio.create_task(
                        self._process_single_file(
                            session=session,
                            file_path=file_path,
                            skip_types=skip_types,
                            project_info=project_info,
                            style_guidelines=style_guidelines,
                            task_id=task_id
                        )
                    )
                    tasks.append(task)

                total = len(tasks)
                completed = 0

                for future in asyncio.as_completed(tasks):
                    try:
                        result = await future
                        if result:
                            self.active_tasks[task_id]["results"]["successful"].append(result)
                        else:
                            self.active_tasks[task_id]["results"]["failed"].append(result)
                    except Exception as e:
                        logger.error(f"Task failed: {e}")
                        self.active_tasks[task_id]["results"]["failed"].append(str(e))

                    completed += 1
                    progress = (completed / total) * 100
                    self.active_tasks[task_id]["progress"] = progress
                    
                    # Generate frontend-compatible response format
                    await self._update_frontend_data(task_id, completed, total)

            self.active_tasks[task_id]["status"] = "completed"
            return self.active_tasks[task_id]["results"]

        except Exception as e:
            logger.error(f"Error in process_files: {e}")
            self.active_tasks[task_id]["status"] = "failed"
            self.active_tasks[task_id]["error"] = str(e)
            return self.active_tasks[task_id]["results"]

    async def _update_frontend_data(self, task_id: str, completed: int, total: int):
        """
        Updates the data structure used by the frontend.
        """
        output_dir = self.output_dir / task_id
        output_dir.mkdir(parents=True, exist_ok=True)

        # Write progress and status
        status_file = output_dir / "status.json"
        status_data = {
            "progress": (completed / total) * 100,
            "status": self.active_tasks[task_id]["status"],
            "completed": completed,
            "total": total,
            "successful": len(self.active_tasks[task_id]["results"]["successful"]),
            "failed": len(self.active_tasks[task_id]["results"]["failed"]),
            "skipped": len(self.active_tasks[task_id]["results"]["skipped"])
        }

        async with aiofiles.open(status_file, 'w') as f:
            await f.write(json.dumps(status_data, indent=2))

        # Write summary data for frontend
        summary_file = output_dir / "summary.json"
        summary_data = {
            "files": [
                {
                    "path": result.get("file_path", "unknown"),
                    "status": "success",
                    "documentation": {
                        "summary": result.get("summary", ""),
                        "metrics": result.get("metrics", {}),
                        "classes": result.get("classes", []),
                        "functions": result.get("functions", [])
                    }
                }
                for result in self.active_tasks[task_id]["results"]["successful"]
            ],
            "metrics": self._calculate_project_metrics(
                self.active_tasks[task_id]["results"]["successful"]
            )
        }

        async with aiofiles.open(summary_file, 'w') as f:
            await f.write(json.dumps(summary_data, indent=2))

    def _calculate_project_metrics(self, successful_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Calculates aggregate project metrics from individual file metrics.
        """
        if not successful_results:
            return {
                "maintainability_index": 0,
                "complexity": 0,
                "halstead": {
                    "volume": 0,
                    "difficulty": 0,
                    "effort": 0
                }
            }

        total_files = len(successful_results)
        aggregate_metrics = {
            "maintainability_index": sum(r.get("metrics", {}).get("maintainability_index", 0) 
                                       for r in successful_results) / total_files,
            "complexity": sum(r.get("metrics", {}).get("complexity", 0) 
                            for r in successful_results),
            "halstead": {
                "volume": sum(r.get("metrics", {}).get("halstead", {}).get("volume", 0) 
                            for r in successful_results),
                "difficulty": sum(r.get("metrics", {}).get("halstead", {}).get("difficulty", 0) 
                                for r in successful_results) / total_files,
                "effort": sum(r.get("metrics", {}).get("halstead", {}).get("effort", 0) 
                            for r in successful_results)
            }
        }

        return aggregate_metrics

# FastAPI application setup
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize DocumentationProcessManager
manager = DocumentationProcessManager(
    repo_root=os.getenv("REPO_ROOT", ""),
    output_dir=os.getenv("OUTPUT_DIR", "documentation"),
    azure_config={
        "deployment_name": os.getenv("AZURE_OPENAI_DEPLOYMENT"),
        "api_key": os.getenv("AZURE_OPENAI_API_KEY"),
        "endpoint": os.getenv("AZURE_OPENAI_ENDPOINT"),
        "api_version": os.getenv("AZURE_OPENAI_API_VERSION")
    },
    function_schema=load_function_schema("schemas/function_schema.json")
)

@app.post("/api/documentation/generate")
async def generate_documentation(
    request: DocumentationRequest,
    background_tasks: BackgroundTasks
) -> DocumentationResponse:
    task_id = str(uuid.uuid4())
    background_tasks.add_task(
        manager.process_files,
        task_id=task_id,
        file_paths=request.file_paths,
        skip_types=request.skip_types,
        project_info=request.project_info,
        style_guidelines=request.style_guidelines
    )
    return DocumentationResponse(
        task_id=task_id,
        status="started",
        progress=0.0
    )

@app.get("/api/documentation/status/{task_id}")
async def get_documentation_status(task_id: str) -> DocumentationResponse:
    if task_id not in manager.active_tasks:
        raise HTTPException(status_code=404, detail="Task not found")
    
    task_info = manager.active_tasks[task_id]
    return DocumentationResponse(
        task_id=task_id,
        status=task_info["status"],
        progress=task_info["progress"],
        results=task_info["results"] if task_info["status"] == "completed" else None
    )

@app.get("/api/documentation/{project_id}")
async def get_documentation(project_id: str, file_path: Optional[str] = None):
    try:
        output_dir = Path("documentation") / project_id
        if file_path:
            doc_file = output_dir / f"{Path(file_path).stem}.json"
            if not doc_file.exists():
                raise HTTPException(status_code=404, detail="Documentation not found")
            
            async with aiofiles.open(doc_file, 'r') as f:
                return json.loads(await f.read())
        else:
            summary_file = output_dir / "summary.json"
            if not summary_file.exists():
                raise HTTPException(status_code=404, detail="Project summary not found")
            
            async with aiofiles.open(summary_file, 'r') as f:
                return json.loads(await f.read())
                
    except Exception as e:
        logger.error(f"Error fetching documentation: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

```

This implementation provides:

1. **Complete Integration Flow**:
- File processing with progress tracking
- Frontend-compatible data structures
- Real-time status updates
- Project-wide metrics calculation

2. **API Endpoints**:
- Documentation generation
- Status checking
- Documentation retrieval

3. **Data Management**:
- Progress tracking
- Error handling
- Results aggregation
- Frontend-compatible format generation

To use this with the frontend, you would:

1. Start the documentation generation:
```typescript
const response = await fetch('/api/documentation/generate', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    project_id: 'your-project-id',
    file_paths: ['path/to/file1.py', 'path/to/file2.py'],
    project_info: 'Project context...',
    style_guidelines: 'Documentation guidelines...'
  })
});

const { task_id } = await response.json();
```

2. Poll for status:
```typescript
const checkStatus = async (taskId: string) => {
  const response = await fetch(`/api/documentation/status/${taskId}`);
  const status = await response.json();
  return status;
};
```

3. Fetch documentation:
```typescript
const getDocumentation = async (projectId: string, filePath?: string) => {
  const url = `/api/documentation/${projectId}${filePath ? `?file_path=${filePath}` : ''}`;
  const response = await fetch(url);
  const documentation = await response.json();
  return documentation;
};
```

The Python backend handles:
- File processing
- Documentation generation
- Progress tracking
- Data formatting
- Error handling
- Frontend integration

Would you like me to elaborate on any specific part of this implementation?
